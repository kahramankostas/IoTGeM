{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "evaluate={'Acc':\"Accuracy\", 'b_Acc':\"Balanced Accuracy\", 'F1':\"F1 Score\", 'kap':\"Kappa\", 'ROC':\"Roc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(f_name): #this function creates a folder named \"attacks\" in the program directory.\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))  \n",
    "            \n",
    "    return files_add\n",
    "\n",
    "files_add=find_the_way(\"SM\",\".csv\")\n",
    "files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_list={\"DT\":DecisionTreeClassifier()}#,\"SVC\":SVC()}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_name(name):\n",
    "    df = pd.read_csv(name,usecols=[\"Label\"])\n",
    "    target_names=sorted(list(df[\"Label\"].unique()))\n",
    "    return target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder(\"results/compare/SS/\")\n",
    "folder(\"results/compare/CV/\")\n",
    "folder(\"results/compare/DD/\")\n",
    "folder(\"pdfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(train_time,test_time,predict,y_test,class_based_results,repeat,cv,dname,ml,sw):\n",
    "    train_time=train_time[0]\n",
    "    test_time=test_time[0]\n",
    "    rc=sklearn.metrics.recall_score(y_test, predict,average= \"macro\")\n",
    "    pr=sklearn.metrics.precision_score(y_test, predict,average= \"macro\")\n",
    "    f_1=sklearn.metrics.f1_score(y_test, predict,average= \"macro\")     \n",
    "    accuracy=sklearn.metrics.accuracy_score(y_test, predict)\n",
    "    accuracy_b=sklearn.metrics.balanced_accuracy_score( y_test,predict)\n",
    "    kappa=sklearn.metrics.cohen_kappa_score(y_test, predict,labels=None, weights=None, sample_weight=None)\n",
    "    try:\n",
    "        roc=sklearn.metrics.roc_auc_score(y_test, predict)\n",
    "    except:roc=0\n",
    "    report = sklearn.metrics.classification_report(y_test, predict, target_names=target_names,output_dict=True)\n",
    "    cr = pd.DataFrame(report).transpose()\n",
    "    line=[dname,sw,repeat,cv,ml,accuracy,accuracy_b,pr,rc,f_1,kappa,roc,train_time,test_time]\n",
    "\n",
    "    if class_based_results.empty:\n",
    "        class_based_results =cr\n",
    "    else:\n",
    "        class_based_results = class_based_results.add(cr, fill_value=0)\n",
    "    return class_based_results,line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML(loop1,loop2,output_csv,cols,dname,sw):\n",
    "    fold=5\n",
    "    repetition=25\n",
    "    for ii in ml_list:\n",
    "        class_based_results=pd.DataFrame()#\"\" #pd.DataFrame(0, index=np.arange((len(target_names)+3)), columns=[\"f1-score\",\"precision\",\"recall\",\"support\"])\n",
    "        cm=pd.DataFrame()\n",
    "        cv=0\n",
    "        lines=[[\"Attack\",\"Feature\",\"T\",\"CV\",\"ML\",\"Acc\",\"b_Acc\",\"Prec\",\"Rec\",\"F1\",\"kap\",\"ROC\",\"tra-T\",\"test-T\"]]\n",
    "        for i in range(repetition):\n",
    "\n",
    "                df = pd.read_csv(loop1,usecols=cols)#,header=None )\n",
    "                df=df.fillna(0)\n",
    "                X_train =df[df.columns[0:-1]]\n",
    "                X_train=np.array(X_train)\n",
    "                df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "                y_train=df[df.columns[-1]].cat.codes  \n",
    "\n",
    "\n",
    "                df = pd.read_csv(loop2,usecols=cols)#,header=None )\n",
    "                df=df.fillna(0)\n",
    "                X_test =df[df.columns[0:-1]]\n",
    "                X_test=np.array(X_test)\n",
    "                df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "                y_test=df[df.columns[-1]].cat.codes  \n",
    "\n",
    "\n",
    "                #dname=loop1  [6:-13]  \n",
    "                results_y=[]\n",
    "       \n",
    "                results_y.append(y_test)\n",
    "\n",
    "\n",
    "                precision=[]\n",
    "                recall=[]\n",
    "                f1=[]\n",
    "                accuracy=[]\n",
    "                train_time=[]\n",
    "                test_time=[]\n",
    "                total_time=[]\n",
    "                kappa=[]\n",
    "                accuracy_b=[]\n",
    "\n",
    "                    #machine learning algorithm is applied in this section\n",
    "                clf = ml_list[ii]#choose algorithm from ml_list dictionary\n",
    "                second=time.time()\n",
    "                clf.fit(X_train, y_train)\n",
    "                train_time.append(float((time.time()-second)) )\n",
    "                second=time.time()\n",
    "                predict =clf.predict(X_test)\n",
    "                test_time.append(float((time.time()-second)) )\n",
    "    \n",
    "                altime=0\n",
    "                class_based_results,line=score(train_time,test_time,predict,y_test,class_based_results,cv,i,dname,ii,sw)\n",
    "                lines.append(line)\n",
    "\n",
    "        results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "        results.to_csv(output_csv.replace(\"ML\",ii),index=False)\n",
    "       \n",
    "        results=results.mean()\n",
    "        results=results.round(3)\n",
    "        #print (tabulate(results, headers=list(results.columns)))\n",
    "        #print()\n",
    "        return list(results.values)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_CV(loop1,loop2,output_csv,cols,dname,sw):\n",
    "    fold=5\n",
    "    repetition=5\n",
    "    for ii in ml_list:\n",
    "        class_based_results=pd.DataFrame()#\"\" #pd.DataFrame(0, index=np.arange((len(target_names)+3)), columns=[\"f1-score\",\"precision\",\"recall\",\"support\"])\n",
    "        cm=pd.DataFrame()\n",
    "        cv=0\n",
    "        lines=[[\"Attack\",\"Feature\",\"T\",\"CV\",\"ML\",\"Acc\",\"b_Acc\",\"Prec\",\"Rec\",\"F1\",\"kap\",\"ROC\",\"tra-T\",\"test-T\"]]\n",
    "        for i in range(repetition):\n",
    "\n",
    "            rnd = random()\n",
    "            \n",
    "            kfold = sklearn.model_selection.KFold(n_splits=fold, shuffle=True, random_state=int(rnd*100))  \n",
    "            cv=0\n",
    "            df = pd.read_csv(loop1,usecols=cols)#,header=None )\n",
    "            ##df = df.reset_index(drop=True)\n",
    "            df=df.fillna(0)\n",
    "\n",
    "            #del df[\"MAC\"] # if dataset has MAC colomn please uncomment this line\n",
    "            X =df[df.columns[0:-1]]\n",
    "            X=np.array(X)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y=df[df.columns[-1]].cat.codes  \n",
    "            X.shape\n",
    "            for train_index, test_index in kfold.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]  \n",
    "\n",
    "                #dname=loop1  [6:-13]  \n",
    "                results_y=[]\n",
    "                cv+=1\n",
    "                results_y.append(y_test)\n",
    "\n",
    "\n",
    "                precision=[]\n",
    "                recall=[]\n",
    "                f1=[]\n",
    "                accuracy=[]\n",
    "                train_time=[]\n",
    "                test_time=[]\n",
    "                total_time=[]\n",
    "                kappa=[]\n",
    "                accuracy_b=[]\n",
    "\n",
    "                    #machine learning algorithm is applied in this section\n",
    "                clf = ml_list[ii]#choose algorithm from ml_list dictionary\n",
    "                second=time.time()\n",
    "                clf.fit(X_train, y_train)\n",
    "                train_time.append(float((time.time()-second)) )\n",
    "                second=time.time()\n",
    "                predict =clf.predict(X_test)\n",
    "                test_time.append(float((time.time()-second)) )\n",
    "    \n",
    "                altime=0\n",
    "                class_based_results,line=score(train_time,test_time,predict,y_test,class_based_results,cv,i,dname,ii,sw)\n",
    "                lines.append(line)\n",
    "\n",
    "        results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "        results.to_csv(output_csv.replace(\"ML\",ii),index=False)\n",
    "\n",
    "        results=results.mean()\n",
    "        results=results.round(3)\n",
    "        #print (tabulate(results, headers=list(results.columns)))\n",
    "        #print()\n",
    "        return list(results.values)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['random', 'ts',#, #'Ether_dst', 'Ether_src', 'IP_src', 'IP_dst', \n",
    "        'pck_size', 'Ether_type', 'LLC_dsap', 'LLC_ssap', 'LLC_ctrl', 'EAPOL_version', 'EAPOL_type', 'EAPOL_len', 'IP_version', 'IP_ihl', 'IP_tos', 'IP_len', 'IP_flags', 'IP_Z', 'IP_MF', 'IP_id', 'IP_chksum', 'IP_DF', 'IP_frag', 'IP_ttl', 'IP_proto', 'IP_options', 'ICMP_type', 'ICMP_code', 'ICMP_chksum', 'ICMP_id', 'ICMP_seq', 'ICMP_ts_ori', 'ICMP_ts_rx', 'ICMP_ts_tx', 'ICMP_ptr', 'ICMP_reserved', 'ICMP_length', 'ICMP_nexthopmtu', #'ICMP_unused',\n",
    "         'TCP_seq', 'TCP_ack', 'TCP_dataofs', 'TCP_reserved', 'TCP_flags', 'TCP_FIN', 'TCP_SYN', 'TCP_RST', \n",
    " 'TCP_PSH', 'TCP_ACK', 'TCP_URG', 'TCP_ECE', 'TCP_CWR', 'TCP_window', 'TCP_chksum', 'TCP_urgptr', 'TCP_options', 'UDP_len', 'UDP_chksum', 'DHCP_options', 'BOOTP_op', 'BOOTP_htype', 'BOOTP_hlen', 'BOOTP_hops', 'BOOTP_xid', 'BOOTP_secs', 'BOOTP_flags', 'BOOTP_sname', 'BOOTP_file', 'BOOTP_options', 'DNS_length', 'DNS_id', 'DNS_qr', 'DNS_opcode', 'DNS_aa', 'DNS_tc', 'DNS_rd', 'DNS_ra', 'DNS_z', 'DNS_ad', 'DNS_cd', 'DNS_rcode', 'DNS_qdcount', 'DNS_ancount', 'DNS_nscount', 'DNS_arcount', 'sport_class', 'dport_class', 'sport23', 'dport23', 'sport_bare', 'dport_bare', 'payload_bytes', 'entropy', 'Protocol',\n",
    " 'dst_IP_diversity', 'dst_port_diversity', 'src_IP_diversity', 'IP_add_count', 'sport', 'dport', #'ID',\n",
    "         'pck_size_diff', 'pck_size_mean_WE', 'pck_size_std_WE', 'pck_size_sum_of_EW', 'ts_diff', 'ts_mean_WE', 'ts_std_WE', 'ts_sum_of_EW', 'TCP_window_diff', 'TCP_window_mean_WE', 'TCP_window_std_WE', 'TCP_window_sum_of_EW', 'payload_bytes_diff', 'payload_bytes_mean_WE', 'payload_bytes_std_WE', 'payload_bytes_sum_of_EW', 'entropy_diff', 'entropy_mean_WE', 'entropy_std_WE', 'entropy_sum_of_EW', 'pck_size_mean_2', 'pck_size_std_2', 'ts_mean_2', 'ts_std_2', 'TCP_window_mean_2', 'TCP_window_std_2', 'payload_bytes_mean_2',\n",
    " 'payload_bytes_std_2', 'entropy_mean_2', 'entropy_std_2', 'dport_sum', 'sport_sum', 'TCP_FIN_sum', 'TCP_SYN_sum', 'TCP_RST_sum', 'TCP_PSH_sum', 'TCP_ACK_sum', 'TCP_URG_sum', 'TCP_ECE_sum', 'TCP_CWR_sum', 'TCP_FIN_ratio', 'TCP_SYN_ratio', 'TCP_RST_ratio', 'TCP_PSH_ratio', 'TCP_ACK_ratio', 'TCP_URG_ratio', 'TCP_ECE_ratio', 'TCP_CWR_ratio', 'sum', 'TCP_FIN_SR', 'TCP_SYN_SR', 'TCP_RST_SR', 'TCP_PSH_SR', 'TCP_ACK_SR', 'TCP_URG_SR', 'TCP_ECE_SR', 'TCP_CWR_SR', 'pck_size_mean_6', 'pck_size_std_6', 'ts_mean_6', 'ts_std_6', 'TCP_window_mean_6', 'TCP_window_std_6', 'payload_bytes_mean_6', 'payload_bytes_std_6',\n",
    " 'entropy_mean_6', 'entropy_std_6', 'pck_size_mean_9', 'pck_size_std_9', 'ts_mean_9', 'ts_std_9', 'TCP_window_mean_9', 'TCP_window_std_9', 'payload_bytes_mean_9', 'payload_bytes_std_9', 'entropy_mean_9', 'entropy_std_9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list={'SM\\\\DoS-SYN-6.csv':\"SYN\",\n",
    "           'SM\\\\MB-ACK-4.csv':\"ACK\",\n",
    "           'SM\\\\MB-BF-3.csv':\"BF\",\n",
    "           'SM\\\\MB-HTTP-4.csv':\"HTTP\",\n",
    "           'SM\\\\MB-UDP-3.csv':\"UDP\",\n",
    "          'SM\\\\MitM-ARP-4.csv':\"ARP\",\n",
    "           'SM\\\\Scan-HDis-3.csv':\"SCHD\",\n",
    "          'SM\\\\Scan-Port-3.csv':\"SP\",\n",
    "          'SM\\\\Scan-OS-3.csv':\"OS\",\n",
    "          'SM\\\\MB-HDis-3.csv':\"MHDis\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train in (file_list):\n",
    "    lines=[[\"Attack\",\"Feature\",\"ML\",\"Acc\",\"b_Acc\",\"Prec\",\"Rec\",\"F1\",\"kap\",\"ROC\",\"tra-T\",\"test-T\"]]\n",
    "    for dname in tqdm(features):\n",
    "        try:\n",
    "            target_names=[\"attack\",\"benign\"]\n",
    "            feature=[dname, 'Label']\n",
    "            output_csv=f\"./results/compare/CV/DT_{file_list[train]}_{dname}.csv\"\n",
    "            #print(f\"{list[train]} Dataset - Feature {number+1}/{len(features)}\")\n",
    "            temp=ML_CV(train,\"\",output_csv,feature,dname,file_list[train])\n",
    "            temp=temp[2:]\n",
    "            temp=[file_list[train],dname,\"DT\"]+temp\n",
    "            lines.append(temp)\n",
    "            \n",
    "        except:\n",
    "            print(\"#\"*110)\n",
    "            print(f\"ERROR ABOUT {list[train]} Dataset - Feature {dname}\")\n",
    "            print(\"#\"*110+\"\\n\\n\")\n",
    "\n",
    "    results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "    print (tabulate(results, headers=list(results.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list={\"SYN\":['SM\\\\DoS-SYN-6.csv','SM\\\\DoS-SYN-5.csv'],\n",
    "\"ACK\":['SM\\\\MB-ACK-4.csv','SM\\\\MB-ACK-3.csv'],\n",
    "\"BF\":['SM\\\\MB-BF-3.csv','SM\\\\MB-BF-5.csv'],\n",
    "\"HTTP\":['SM\\\\MB-HTTP-4.csv','SM\\\\MB-HTTP-2.csv'],\n",
    "\"UDP\":['SM\\\\MB-UDP-3.csv','SM\\\\MB-UDP-2.csv'],\n",
    "\"ARP\":['SM\\\\MitM-ARP-4.csv','SM\\\\MitM-ARP-3.csv'],\n",
    "\"SCHD\":['SM\\\\Scan-HDis-3.csv','SM\\\\Scan-HDis-5.csv'],\n",
    "\"SP\":['SM\\\\Scan-Port-3.csv','SM\\\\Scan-Port-4.csv'],\n",
    "\"OS\":['SM\\\\Scan-OS-3.csv','SM\\\\Scan-OS-2.csv'],\n",
    "\"MHDis\":['SM\\\\MB-HDis-3.csv','SM\\\\MB-HDis-5.csv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train in (file_list):\n",
    "    lines=[[\"Attack\",\"Feature\",\"ML\",\"Acc\",\"b_Acc\",\"Prec\",\"Rec\",\"F1\",\"kap\",\"ROC\",\"tra-T\",\"test-T\"]]\n",
    "    for dname in tqdm(features):\n",
    "        try:\n",
    "            target_names=[\"attack\",\"benign\"]\n",
    "            feature=[dname, 'Label']\n",
    "            \n",
    "            output_csv=f\"./results/compare/SS/DT_{train}_{dname}.csv\"\n",
    "            temp=ML(file_list[train][0],file_list[train][1],output_csv,feature,dname,train)  \n",
    "            temp=temp[2:]\n",
    "            temp=[train,dname,\"DT\"]+temp\n",
    "            lines.append(temp)\n",
    "        except:\n",
    "            print(\"#\"*110)\n",
    "            print(f\"ERROR ABOUT {list[train]} Dataset - Feature {dname}\")\n",
    "            print(\"#\"*110+\"\\n\\n\")\n",
    "\n",
    "    results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "    print (tabulate(results, headers=list(results.columns)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buradasin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_add=find_the_way(\"./VAL\",\".csv\")\n",
    "files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list={\"SYN\":['SM\\\\DoS-SYN-6.csv', './VAL/Maze_SYN.csv'],\n",
    "\"ACK\":['SM\\\\MB-ACK-4.csv', './VAL/Maze_ACK.csv'],\n",
    "\"BF\":['SM\\\\MB-BF-3.csv', './VAL/Kitsune_Mir_BF.csv'],\n",
    "\"HTTP\":['SM\\\\MB-HTTP-4.csv', './VAL/Maze_HTTP.csv'],\n",
    "\"UDP\":['SM\\\\MB-UDP-3.csv', './VAL/BoT-IoT-UDP_DDoS.csv'],\n",
    "\"ARP\":['SM\\\\MitM-ARP-4.csv', './VAL/TON_MitM.csv'],\n",
    "\"SCHD\":['SM\\\\Scan-HDis-3.csv','./VAL/Scan-HDis.csv'],\n",
    "\"SP\":['SM\\\\Scan-Port-3.csv', './VAL/Edge-IIoTset_Port_Scan.csv'],\n",
    "\"OS\":['SM\\\\Scan-OS-3.csv','./VAL/BoT-IoT_OSScan.csv'],\n",
    "\"MHDis\":['SM\\\\MB-HDis-3.csv','./VAL/MB-HDis.csv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in file_list:\n",
    "    print(i)\n",
    "    df=pd.read_csv(file_list[i][0])\n",
    "    print(df.groupby(\"Label\").size())\n",
    "    print(\"_\"*120)\n",
    "    df=pd.read_csv(file_list[i][1])\n",
    "    print(df.groupby(\"Label\").size())\n",
    "    print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train in (file_list):\n",
    "    lines=[[\"Attack\",\"Feature\",\"ML\",\"Acc\",\"b_Acc\",\"Prec\",\"Rec\",\"F1\",\"kap\",\"ROC\",\"tra-T\",\"test-T\"]]\n",
    "    for dname in tqdm(features):\n",
    "        try:\n",
    "            target_names=[\"attack\",\"benign\"]\n",
    "            feature=[dname, 'Label']\n",
    "            \n",
    "            output_csv=f\"./results/compare/DD/DT_{train}_{dname}.csv\"\n",
    "            temp=ML(file_list[train][0],file_list[train][1],output_csv,feature,dname,train)  \n",
    "            temp=temp[2:]\n",
    "            temp=[train,dname,\"DT\"]+temp\n",
    "            lines.append(temp)\n",
    "        except:\n",
    "            print(\"#\"*110)\n",
    "            print(f\"ERROR ABOUT {list[train]} Dataset - Feature {dname}\")\n",
    "            print(\"#\"*110+\"\\n\\n\")\n",
    "\n",
    "    results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "    print (tabulate(results, headers=list(results.columns)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders=[\"CV\",\"SS\",\"DD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[['Attack', 'Feature', \"Folder\", 'T', 'CV', 'Acc', 'b_Acc', 'Prec', 'Rec',\n",
    "       'F1', 'kap', 'ROC', 'tra-T', 'test-T']]\n",
    "\n",
    "for f in [\"CV\",\"SS\",\"DD\"]:\n",
    "    files_add=find_the_way(f\"./results\\\\compare\\\\{f}\",\".csv\")\n",
    "    for i in tqdm(files_add):\n",
    "        df=pd.read_csv(i)\n",
    "        temp=df.values\n",
    "        df=df.mean()\n",
    "        df=list(df.values)\n",
    "        temp=list(temp[0][:2])\n",
    "        temp.append(f)\n",
    "        temp=temp+df\n",
    "        results.append(temp)\n",
    "results = pd.DataFrame (results[1:], columns = results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method={\"CV\":\"Cross-validation\",\"SS\":\"2 Diffirent Sessions\",\"DD\":\"2 Diffirent Dataset\" }\n",
    "import matplotlib.pylab as pylab\n",
    "sns.set_style(\"whitegrid\")\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (35, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "for i in results[\"Feature\"].unique():    \n",
    "    graph_name=f\"./pdfs/Comparison_f1_{i}.pdf\"\n",
    "    plt.margins(x=0)\n",
    "    \n",
    "    df=results[results[\"Feature\"]==i]\n",
    "    for ii in results[\"Folder\"].unique():\n",
    "        sf=df[df[\"Folder\"]==ii]\n",
    "        my_xticks=sf[\"Attack\"]#list(iso.index)\n",
    "        pylab.rcParams.update(params)\n",
    "        #plt.figure(figsize=(10,10))\n",
    "        #plt.plot(my_xticks,iso['Acc'], linestyle='--', marker='.', color='b',label= \"Separate Train & Test acc\")\n",
    "        #plt.plot(my_xticks,cv['Acc'], linestyle='--', marker='.', color='r',label= \"10-Fold CV acc\")\n",
    "        plt.plot(my_xticks,sf['F1'], linestyle='-', marker='o',label= method[ii])\n",
    "    #plt.plot(my_xticks,iso[' F1-score'], linestyle='-', marker='o', color='m',label= \"Diffirent Dataset Isolated\")\n",
    "    #plt.plot(my_xticks,cv[' F1-score'], linestyle='-', marker='o', color='b',label= \"5-Fold CV\")\n",
    "    #plt.axhline(0.492885, color='r',label= \"Primary feature list\")\n",
    "    #plt.axhline(0.443367, color='r',label= \"Primary feature list\")\n",
    "    plt.title(f\"Comparison of isolated and cross-validated data result for {i} attack \")\n",
    "    plt.legend(numpoints=1)\n",
    "    #plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.xticks(rotation=90) \n",
    "    #plt.ylim([0.69, 0.71]) \n",
    "    plt.savefig(graph_name,bbox_inches='tight',format=\"pdf\")#, dpi=400)\n",
    "    plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method={\"CV\":\"Cross-validation\",\"SS\":\"2 Diffirent Sessions\",\"DD\":\"2 Diffirent Dataset\" }\n",
    "import matplotlib.pylab as pylab\n",
    "sns.set_style(\"whitegrid\")\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (35, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "for i in results[\"Feature\"].unique():    \n",
    "    graph_name=f\"./pdfs/Comparison_kappa_{i}.pdf\"\n",
    "    plt.margins(x=0)\n",
    "    temp=[]\n",
    "    df=results[results[\"Feature\"]==i]\n",
    "    for ii in results[\"Folder\"].unique():\n",
    "        sf=df[df[\"Folder\"]==ii]\n",
    "        my_xticks=sf[\"Attack\"]#list(iso.index)\n",
    "        pylab.rcParams.update(params)\n",
    "        temp.append(sf['kap'].values)\n",
    "        #plt.figure(figsize=(10,10))\n",
    "        #plt.plot(my_xticks,iso['Acc'], linestyle='--', marker='.', color='b',label= \"Separate Train & Test acc\")\n",
    "        #plt.plot(my_xticks,cv['Acc'], linestyle='--', marker='.', color='r',label= \"10-Fold CV acc\")\n",
    "        plt.plot(my_xticks,sf['kap'], linestyle='-', marker='o',label= method[ii])\n",
    "    #plt.plot(my_xticks,iso[' F1-score'], linestyle='-', marker='o', color='m',label= \"Diffirent Dataset Isolated\")\n",
    "    #plt.plot(my_xticks,cv[' F1-score'], linestyle='-', marker='o', color='b',label= \"5-Fold CV\")\n",
    "    #plt.axhline(0.492885, color='r',label= \"Primary feature list\")\n",
    "    #plt.axhline(0.443367, color='r',label= \"Primary feature list\")\n",
    "    plt.title(f\"Comparison of isolated and cross-validated data result for {i} attack \")\n",
    "    plt.legend(numpoints=1)\n",
    "    #plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    plt.ylabel(\"Kappa\")\n",
    "    plt.xticks(rotation=90) \n",
    "    #plt.ylim([0.69, 0.71]) \n",
    "    plt.savefig(graph_name,bbox_inches='tight',format=\"pdf\")#, dpi=400)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IDF=['DNS_id',\n",
    "'dport',\n",
    "'dport_bare',\n",
    "'dport23',\n",
    "'Ether_dst',\n",
    "'ICMP_chksum',\n",
    "'ICMP_id',\n",
    "'ICMP_seq',\n",
    "'ICMP_unused',\n",
    "'ID',\n",
    "'IP_chksum',\n",
    "'IP_dst',\n",
    "'IP_id',\n",
    "'IP_src',\n",
    "'sport',\n",
    "'sport_bare',\n",
    "'sport23',\n",
    "'sum',\n",
    "'TCP_ack',\n",
    "'TCP_ACK_sum',\n",
    "'TCP_chksum',\n",
    "'TCP_CWR_sum',\n",
    "'TCP_ECE_sum',\n",
    "'TCP_FIN_sum',\n",
    "'TCP_PSH_sum',\n",
    "'TCP_RST_sum',\n",
    "'TCP_seq',\n",
    "'TCP_SYN_sum',\n",
    "'TCP_URG_sum',\n",
    "'UDP_chksum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA_input={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method={\"CV\":\"Cross-validation\",\"SS\":\"2 Diffirent Sessions\",\"DD\":\"2 Diffirent Dataset\" }\n",
    "import matplotlib.pylab as pylab\n",
    "for attack in results[\"Feature\"].unique():\n",
    "    print(f\"____________________________________{attack}________________________________________________________\")\n",
    "    #plt.margins(x=0)\n",
    "    temp=[]\n",
    "    df=results[results[\"Feature\"]==attack]\n",
    "    for ii in results[\"Folder\"].unique():\n",
    "        sf=df[df[\"Folder\"]==ii]\n",
    "        my_xticks=sf[\"Attack\"]#list(iso.index)\n",
    "        temp.append(sf['kap'].values)   \n",
    "    itself=[]\n",
    "    same=[]\n",
    "    diff=[]\n",
    "    my_xticks=my_xticks.values\n",
    "    flag=1\n",
    "    for j in range(len(temp[0])):\n",
    "        if temp[0][j]>0:\n",
    "            itself.append(my_xticks[j])\n",
    "        if temp[1][j]>0:\n",
    "            same.append(my_xticks[j])\n",
    "        if temp[2][j]>0:\n",
    "            diff.append(my_xticks[j])\n",
    "    itself.append(\"Label\")\n",
    "    same.append(\"Label\")\n",
    "    diff.append(\"Label\")\n",
    "        \n",
    "    for j in [itself,same]:\n",
    "        print(len(j))\n",
    "        print(f\"{j}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    c1 = Counter(diff)\n",
    "    c2 = Counter(IDF)\n",
    "    diff = list((c1 - c2).elements())\n",
    "    print(len(diff))\n",
    "    print(f\"{diff}\\n\\n\")\n",
    "    main=itself+same+diff\n",
    "    GA_input[attack]=diff\n",
    "    main=set(main)\n",
    "    mainlist=[]\n",
    "    for i in main:\n",
    "        temp=[i,int(i in itself),int(i in same),int(i in diff)]\n",
    "        mainlist.append(temp)\n",
    "        \n",
    "    data=pd.DataFrame(mainlist, columns=[\"Feature\", \"itself\",\"same\",\"diffirent\"]).set_index('Feature')\n",
    "    graph_name=f\"./pdfs/kappa_{attack}_Voting2.PDF\"\n",
    "    import seaborn as sns\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "    plt.rcParams.update(params)\n",
    "    import matplotlib.pylab as pylab\n",
    "\n",
    "    #pylab.rcParams.update(params)\n",
    "\n",
    "    data.plot.bar(stacked=True,figsize=(28,5))\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Votes')\n",
    "    plt.savefig(graph_name,bbox_inches='tight',format=\"pdf\")#, dpi=400)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('GA_input.json', 'w') as fp:\n",
    "    json.dump(GA_input, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
